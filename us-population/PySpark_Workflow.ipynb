{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff31285-8fc8-491f-a4ef-7ef386a2ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "import pyspark\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862c1c60-3a13-438d-8750-9da8601cfbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/pybokeh/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02570dc0-cb3d-4374-aeea-72d53a6b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "try:\n",
    "    config.read(config_file)\n",
    "except ConfigFileNotFound:\n",
    "    print(\"config.ini file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f52f219-8cb3-40f5-a51f-2a44cde2e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_jdbc_driver = Path(config['postgresql']['jdbc_driver_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691c789c-44f1-4aab-bf36-f0fd05708a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Postgresql database credentials for DSN-less connection\n",
    "pg_host = config[\"postgresql\"][\"host\"]\n",
    "pg_port = config[\"postgresql\"][\"port\"]\n",
    "pg_db = config[\"postgresql\"][\"database\"]\n",
    "pg_user = config[\"postgresql\"][\"username\"]\n",
    "pg_pwd = config[\"postgresql\"][\"password\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e2a7be-c7ed-4085-8e7e-32b906980aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'jdbc:postgresql://{pg_host}:{pg_port}/{pg_db}'\n",
    "driver = 'org.postgresql.Driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3f772f-2346-45c8-849c-2344f315c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/21 03:24:10 WARN Utils: Your hostname, pybokeh-Lemur resolves to a loopback address: 127.0.1.1; using 192.168.1.147 instead (on interface wlp2s0)\n",
      "23/05/21 03:24:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/05/21 03:24:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.master(\"local[*]\")\n",
    "    .appName(\"Postgres\")\n",
    "    .config(\"spark.jars\", postgres_jdbc_driver)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054485bb-12a8-4e21-8d03-f0ae88819b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * from public.us_counties_pop_est_2010_2019_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450018d1-86f4-4e71-b04f-c04b2b9643fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties_pop_est_2010_2019_raw = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"query\", \"SELECT * from public.us_counties_pop_est_2010_2019_raw\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f91394-5ffc-49e1-9e1b-43d5279d3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"query\", \"SELECT * from public.regions\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3163410-b8ff-4b8a-beb5-b18be3c31e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"query\", \"SELECT * from public.divisions\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e62d96-63a0-4675-be90-a3f7474563c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sumlev',\n",
       " 'region',\n",
       " 'division',\n",
       " 'state',\n",
       " 'county',\n",
       " 'stname',\n",
       " 'ctyname',\n",
       " 'census2010pop',\n",
       " 'estimatesbase2010',\n",
       " 'popestimate2010',\n",
       " 'popestimate2011',\n",
       " 'popestimate2012',\n",
       " 'popestimate2013',\n",
       " 'popestimate2014',\n",
       " 'popestimate2015',\n",
       " 'popestimate2016',\n",
       " 'popestimate2017',\n",
       " 'popestimate2018',\n",
       " 'popestimate2019',\n",
       " 'npopchg_2010']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_counties_pop_est_2010_2019_raw.columns[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "407ae4d1-497f-4dd6-99c5-17ce621b07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|region|region_name|\n",
      "+------+-----------+\n",
      "|     1|  Northeast|\n",
      "|     2|    Midwest|\n",
      "|     3|      South|\n",
      "|     4|       West|\n",
      "+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a43c0374-6fb7-4ca5-b39f-cc139bcc0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|division|     division_name|\n",
      "+--------+------------------+\n",
      "|       1|       New England|\n",
      "|       2|   Middle Atlantic|\n",
      "|       3|East North Central|\n",
      "|       4|West North Central|\n",
      "|       5|    South Atlantic|\n",
      "|       6|East South Central|\n",
      "|       7|West South Central|\n",
      "|       8|           Montain|\n",
      "|       9|           Pacific|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e3679-b9fa-4261-88f9-b8e3c48585c8",
   "metadata": {},
   "source": [
    "#### Let's merge the 3 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a46fdae-14b0-4b85-bb9d-1be13e14a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = (\n",
    "    us_counties_pop_est_2010_2019_raw.select(\n",
    "        [\n",
    "            col('state').alias('state_fips'),\n",
    "            col('county').alias('county_fips'),\n",
    "            col('stname').alias('state_name'),\n",
    "            col('ctyname').alias('county_name'),\n",
    "            col('region'),\n",
    "            col('division'),\n",
    "            col('census2010pop'),\n",
    "            col('estimatesbase2010')\n",
    "        ] +\n",
    "        [col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^popestimate20\\d{2}$', column)] +\n",
    "        [col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^births20\\d{2}$', column)] +\n",
    "        [col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^deaths20\\d{2}$', column)]\n",
    "    ).join(\n",
    "        regions,\n",
    "        us_counties_pop_est_2010_2019_raw.region == regions.region,\n",
    "        'left'\n",
    "    ).join(\n",
    "        divisions,\n",
    "        us_counties_pop_est_2010_2019_raw.division == divisions.division,\n",
    "        'left'\n",
    "    )\n",
    "    .drop(regions.region)\n",
    "    .drop(divisions.division)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61852cc-cd8d-48d3-abce-b1159c9b777e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_fips',\n",
       " 'county_fips',\n",
       " 'state_name',\n",
       " 'county_name',\n",
       " 'region',\n",
       " 'division',\n",
       " 'census2010pop',\n",
       " 'estimatesbase2010',\n",
       " 'popestimate2010',\n",
       " 'popestimate2011',\n",
       " 'popestimate2012',\n",
       " 'popestimate2013',\n",
       " 'popestimate2014',\n",
       " 'popestimate2015',\n",
       " 'popestimate2016',\n",
       " 'popestimate2017',\n",
       " 'popestimate2018',\n",
       " 'popestimate2019',\n",
       " 'births2010',\n",
       " 'births2011',\n",
       " 'births2012',\n",
       " 'births2013',\n",
       " 'births2014',\n",
       " 'births2015',\n",
       " 'births2016',\n",
       " 'births2017',\n",
       " 'births2018',\n",
       " 'births2019',\n",
       " 'deaths2010',\n",
       " 'deaths2011',\n",
       " 'deaths2012',\n",
       " 'deaths2013',\n",
       " 'deaths2014',\n",
       " 'deaths2015',\n",
       " 'deaths2016',\n",
       " 'deaths2017',\n",
       " 'deaths2018',\n",
       " 'deaths2019',\n",
       " 'region_name',\n",
       " 'division_name']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b1adc-3cd2-4b17-9889-8a67cd1e1b0e",
   "metadata": {},
   "source": [
    "#### One problem is 'region_name' and 'division_name' columns are at the end, so need to re-arrange the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "595e422a-a7d0-410d-94c6-e37677ec1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    col('state_fips'),\n",
    "    col('county_fips'),\n",
    "    col('state_name'),\n",
    "    col('county_name'),\n",
    "    col('region_name'),\n",
    "    col('division_name'),\n",
    "    col('census2010pop'),\n",
    "    col('estimatesbase2010')\n",
    "] + [\n",
    "    col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^popestimate20\\d{2}$', column)\n",
    "] + [\n",
    "    col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^births20\\d{2}$', column)\n",
    "] + [\n",
    "    col(column) for column in us_counties_pop_est_2010_2019_raw.columns if re.match(r'^deaths20\\d{2}$', column)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e8fc015-b55c-4f0f-bd70-5ffe96a988ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_fips',\n",
       " 'county_fips',\n",
       " 'state_name',\n",
       " 'county_name',\n",
       " 'region_name',\n",
       " 'division_name',\n",
       " 'census2010pop',\n",
       " 'estimatesbase2010',\n",
       " 'popestimate2010',\n",
       " 'popestimate2011',\n",
       " 'popestimate2012',\n",
       " 'popestimate2013',\n",
       " 'popestimate2014',\n",
       " 'popestimate2015',\n",
       " 'popestimate2016',\n",
       " 'popestimate2017',\n",
       " 'popestimate2018',\n",
       " 'popestimate2019',\n",
       " 'births2010',\n",
       " 'births2011',\n",
       " 'births2012',\n",
       " 'births2013',\n",
       " 'births2014',\n",
       " 'births2015',\n",
       " 'births2016',\n",
       " 'births2017',\n",
       " 'births2018',\n",
       " 'births2019',\n",
       " 'deaths2010',\n",
       " 'deaths2011',\n",
       " 'deaths2012',\n",
       " 'deaths2013',\n",
       " 'deaths2014',\n",
       " 'deaths2015',\n",
       " 'deaths2016',\n",
       " 'deaths2017',\n",
       " 'deaths2018',\n",
       " 'deaths2019']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.select(selected_columns).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3f8f1-5e0a-4712-a33d-8b815abe0c45",
   "metadata": {},
   "source": [
    "#### The resulting dataframe above has the columns in the order we want, we can then write this dataframe as a PostgreSQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "660db0ef-b58c-4701-a47d-e65f2cb4d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/21 03:26:09 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    temp_df.select(selected_columns)\n",
    "    # The following are needed to write this dataframe as a PostgreSQL table\n",
    "    .write.format(\"jdbc\")\n",
    "    .option(\"url\", url)\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"dbtable\", \"public.us_pop_shortened\")\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.10 (PySpark 3.3.2)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

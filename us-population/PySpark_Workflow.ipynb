{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50db4d6a-c72b-4a96-9016-e0f3fd0d52e8",
   "metadata": {},
   "source": [
    "# Working with PostgreSQL tables using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff31285-8fc8-491f-a4ef-7ef386a2ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "import pyspark\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862c1c60-3a13-438d-8750-9da8601cfbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/pybokeh/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02570dc0-cb3d-4374-aeea-72d53a6b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "try:\n",
    "    config.read(config_file)\n",
    "except ConfigFileNotFound:\n",
    "    print(\"config.ini file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f52f219-8cb3-40f5-a51f-2a44cde2e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_jdbc_driver = Path(config['postgresql']['jdbc_driver_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691c789c-44f1-4aab-bf36-f0fd05708a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Postgresql database credentials for DSN-less connection\n",
    "pg_host = config[\"postgresql\"][\"host\"]\n",
    "pg_port = config[\"postgresql\"][\"port\"]\n",
    "pg_db = config[\"postgresql\"][\"database\"]\n",
    "pg_user = config[\"postgresql\"][\"username\"]\n",
    "pg_pwd = config[\"postgresql\"][\"password\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e2a7be-c7ed-4085-8e7e-32b906980aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'jdbc:postgresql://{pg_host}:{pg_port}/{pg_db}'\n",
    "driver = 'org.postgresql.Driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3f772f-2346-45c8-849c-2344f315c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/21 11:26:22 WARN Utils: Your hostname, pybokeh-Lemur resolves to a loopback address: 127.0.1.1; using 192.168.1.147 instead (on interface wlp2s0)\n",
      "23/05/21 11:26:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/05/21 11:26:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.master(\"local[*]\")\n",
    "    .appName(\"Postgres\")\n",
    "    .config(\"spark.jars\", postgres_jdbc_driver)\n",
    "    .config(\"spark.sql.execution.eagerEval.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c5b06-94bb-47c0-b8cf-310790dd7931",
   "metadata": {},
   "source": [
    "#### Issue metadata query to get information about the database, what tables are available, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e7aa0b-4e0b-48f2-8571-0434aba2d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- table_catalog: string (nullable = true)\n",
      " |-- table_schema: string (nullable = true)\n",
      " |-- table_name: string (nullable = true)\n",
      " |-- table_type: string (nullable = true)\n",
      " |-- self_referencing_column_name: string (nullable = true)\n",
      " |-- reference_generation: string (nullable = true)\n",
      " |-- user_defined_type_catalog: string (nullable = true)\n",
      " |-- user_defined_type_schema: string (nullable = true)\n",
      " |-- user_defined_type_name: string (nullable = true)\n",
      " |-- is_insertable_into: string (nullable = true)\n",
      " |-- is_typed: string (nullable = true)\n",
      " |-- commit_action: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"dbtable\", \"information_schema.tables\")\n",
    "    .load()\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b99f55-e16c-4199-8bd5-ede3789b6da5",
   "metadata": {},
   "source": [
    "#### Let's obtain a list of schemas and table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee6b642-213f-4149-937c-3b4276f84108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------------------+\n",
      "|table_schema|table_name                       |\n",
      "+------------+---------------------------------+\n",
      "|public      |us_counties_pop_est_2010_2019_raw|\n",
      "|public      |regions                          |\n",
      "|public      |divisions                        |\n",
      "+------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"dbtable\", \"information_schema.tables\")\n",
    "    .load()\n",
    "    .filter(col('table_schema') == 'public')\n",
    "    .select(col('table_schema'), col('table_name'))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c857b7-75bd-40a1-802c-c1838939b5b3",
   "metadata": {},
   "source": [
    "#### Let's fetch the 3 tables from Postgres and save them as PySpark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1a7916-3662-4611-8a18-438275abc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_queries = [\n",
    "    \"SELECT * from public.us_counties_pop_est_2010_2019_raw\",\n",
    "    \"SELECT * from public.regions\",\n",
    "    \"SELECT * from public.divisions\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c8bcec-26c3-4643-8947-7949b0409f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for query in select_queries:\n",
    "    dataframe = (\n",
    "        spark.read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"driver\", driver)\n",
    "        .option(\"url\", url)\n",
    "        .option(\"user\", pg_user)\n",
    "        .option(\"password\", pg_pwd)\n",
    "        .option(\"query\", query)\n",
    "        .load()\n",
    "    )\n",
    "    dataframes.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d3ce100-ae06-412f-bb86-7b7945cca793",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties_pop_est_2010_2019_raw = dataframes[0]\n",
    "regions = dataframes[1]\n",
    "divisions = dataframes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789e2796-df3e-4eb8-b57e-f877e7faf882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sumlev: string (nullable = true)\n",
      " |-- region: short (nullable = true)\n",
      " |-- division: short (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- stname: string (nullable = true)\n",
      " |-- ctyname: string (nullable = true)\n",
      " |-- census2010pop: integer (nullable = true)\n",
      " |-- estimatesbase2010: integer (nullable = true)\n",
      " |-- popestimate2010: integer (nullable = true)\n",
      " |-- popestimate2011: integer (nullable = true)\n",
      " |-- popestimate2012: integer (nullable = true)\n",
      " |-- popestimate2013: integer (nullable = true)\n",
      " |-- popestimate2014: integer (nullable = true)\n",
      " |-- popestimate2015: integer (nullable = true)\n",
      " |-- popestimate2016: integer (nullable = true)\n",
      " |-- popestimate2017: integer (nullable = true)\n",
      " |-- popestimate2018: integer (nullable = true)\n",
      " |-- popestimate2019: integer (nullable = true)\n",
      " |-- npopchg_2010: integer (nullable = true)\n",
      " |-- npopchg_2011: integer (nullable = true)\n",
      " |-- npopchg_2012: integer (nullable = true)\n",
      " |-- npopchg_2013: integer (nullable = true)\n",
      " |-- npopchg_2014: integer (nullable = true)\n",
      " |-- npopchg_2015: integer (nullable = true)\n",
      " |-- npopchg_2016: integer (nullable = true)\n",
      " |-- npopchg_2017: integer (nullable = true)\n",
      " |-- npopchg_2018: integer (nullable = true)\n",
      " |-- npopchg_2019: integer (nullable = true)\n",
      " |-- births2010: integer (nullable = true)\n",
      " |-- births2011: integer (nullable = true)\n",
      " |-- births2012: integer (nullable = true)\n",
      " |-- births2013: integer (nullable = true)\n",
      " |-- births2014: integer (nullable = true)\n",
      " |-- births2015: integer (nullable = true)\n",
      " |-- births2016: integer (nullable = true)\n",
      " |-- births2017: integer (nullable = true)\n",
      " |-- births2018: integer (nullable = true)\n",
      " |-- births2019: integer (nullable = true)\n",
      " |-- deaths2010: integer (nullable = true)\n",
      " |-- deaths2011: integer (nullable = true)\n",
      " |-- deaths2012: integer (nullable = true)\n",
      " |-- deaths2013: integer (nullable = true)\n",
      " |-- deaths2014: integer (nullable = true)\n",
      " |-- deaths2015: integer (nullable = true)\n",
      " |-- deaths2016: integer (nullable = true)\n",
      " |-- deaths2017: integer (nullable = true)\n",
      " |-- deaths2018: integer (nullable = true)\n",
      " |-- deaths2019: integer (nullable = true)\n",
      " |-- naturalinc2010: integer (nullable = true)\n",
      " |-- naturalinc2011: integer (nullable = true)\n",
      " |-- naturalinc2012: integer (nullable = true)\n",
      " |-- naturalinc2013: integer (nullable = true)\n",
      " |-- naturalinc2014: integer (nullable = true)\n",
      " |-- naturalinc2015: integer (nullable = true)\n",
      " |-- naturalinc2016: integer (nullable = true)\n",
      " |-- naturalinc2017: integer (nullable = true)\n",
      " |-- naturalinc2018: integer (nullable = true)\n",
      " |-- naturalinc2019: integer (nullable = true)\n",
      " |-- internationalmig2010: integer (nullable = true)\n",
      " |-- internationalmig2011: integer (nullable = true)\n",
      " |-- internationalmig2012: integer (nullable = true)\n",
      " |-- internationalmig2013: integer (nullable = true)\n",
      " |-- internationalmig2014: integer (nullable = true)\n",
      " |-- internationalmig2015: integer (nullable = true)\n",
      " |-- internationalmig2016: integer (nullable = true)\n",
      " |-- internationalmig2017: integer (nullable = true)\n",
      " |-- internationalmig2018: integer (nullable = true)\n",
      " |-- internationalmig2019: integer (nullable = true)\n",
      " |-- domesticmig2010: integer (nullable = true)\n",
      " |-- domesticmig2011: integer (nullable = true)\n",
      " |-- domesticmig2012: integer (nullable = true)\n",
      " |-- domesticmig2013: integer (nullable = true)\n",
      " |-- domesticmig2014: integer (nullable = true)\n",
      " |-- domesticmig2015: integer (nullable = true)\n",
      " |-- domesticmig2016: integer (nullable = true)\n",
      " |-- domesticmig2017: integer (nullable = true)\n",
      " |-- domesticmig2018: integer (nullable = true)\n",
      " |-- domesticmig2019: integer (nullable = true)\n",
      " |-- netmig2010: integer (nullable = true)\n",
      " |-- netmig2011: integer (nullable = true)\n",
      " |-- netmig2012: integer (nullable = true)\n",
      " |-- netmig2013: integer (nullable = true)\n",
      " |-- netmig2014: integer (nullable = true)\n",
      " |-- netmig2015: integer (nullable = true)\n",
      " |-- netmig2016: integer (nullable = true)\n",
      " |-- netmig2017: integer (nullable = true)\n",
      " |-- netmig2018: integer (nullable = true)\n",
      " |-- netmig2019: integer (nullable = true)\n",
      " |-- residual2010: integer (nullable = true)\n",
      " |-- residual2011: integer (nullable = true)\n",
      " |-- residual2012: integer (nullable = true)\n",
      " |-- residual2013: integer (nullable = true)\n",
      " |-- residual2014: integer (nullable = true)\n",
      " |-- residual2015: integer (nullable = true)\n",
      " |-- residual2016: integer (nullable = true)\n",
      " |-- residual2017: integer (nullable = true)\n",
      " |-- residual2018: integer (nullable = true)\n",
      " |-- residual2019: integer (nullable = true)\n",
      " |-- gqestimatesbase2010: integer (nullable = true)\n",
      " |-- gqestimates2010: integer (nullable = true)\n",
      " |-- gqestimates2011: integer (nullable = true)\n",
      " |-- gqestimates2012: integer (nullable = true)\n",
      " |-- gqestimates2013: integer (nullable = true)\n",
      " |-- gqestimates2014: integer (nullable = true)\n",
      " |-- gqestimates2015: integer (nullable = true)\n",
      " |-- gqestimates2016: integer (nullable = true)\n",
      " |-- gqestimates2017: integer (nullable = true)\n",
      " |-- gqestimates2018: integer (nullable = true)\n",
      " |-- gqestimates2019: integer (nullable = true)\n",
      " |-- rbirth2011: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2012: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2013: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2014: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2015: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2016: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2017: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2018: decimal(15,10) (nullable = true)\n",
      " |-- rbirth2019: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2011: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2012: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2013: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2014: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2015: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2016: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2017: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2018: decimal(15,10) (nullable = true)\n",
      " |-- rdeath2019: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2011: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2012: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2013: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2014: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2015: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2016: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2017: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2018: decimal(15,10) (nullable = true)\n",
      " |-- rnaturalinc2019: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2011: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2012: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2013: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2014: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2015: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2016: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2017: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2018: decimal(15,10) (nullable = true)\n",
      " |-- rinternationalmig2019: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2011: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2012: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2013: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2014: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2015: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2016: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2017: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2018: decimal(15,10) (nullable = true)\n",
      " |-- rdomesticmig2019: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2011: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2012: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2013: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2014: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2015: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2016: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2017: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2018: decimal(15,10) (nullable = true)\n",
      " |-- rnetmig2019: decimal(15,10) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_counties_pop_est_2010_2019_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "188dfba6-36bb-4109-9b59-7b8c29ed3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|region|region_name|\n",
      "+------+-----------+\n",
      "|     1|  Northeast|\n",
      "|     2|    Midwest|\n",
      "|     3|      South|\n",
      "|     4|       West|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ca7044-226e-40de-89fa-e027ba174b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|division|     division_name|\n",
      "+--------+------------------+\n",
      "|       1|       New England|\n",
      "|       2|   Middle Atlantic|\n",
      "|       3|East North Central|\n",
      "|       4|West North Central|\n",
      "|       5|    South Atlantic|\n",
      "|       6|East South Central|\n",
      "|       7|West South Central|\n",
      "|       8|           Montain|\n",
      "|       9|           Pacific|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e3679-b9fa-4261-88f9-b8e3c48585c8",
   "metadata": {},
   "source": [
    "#### Let's merge the 3 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ff98ab-cf60-43d7-b225-925158cb8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = (\n",
    "    us_counties_pop_est_2010_2019_raw.select(\n",
    "        col('state').alias('state_fips'),\n",
    "        col('county').alias('county_fips'),\n",
    "        col('stname').alias('state_name'),\n",
    "        col('ctyname').alias('county_name'),\n",
    "        col('region'),\n",
    "        col('division'),\n",
    "        col('census2010pop'),\n",
    "        col('estimatesbase2010'),\n",
    "        us_counties_pop_est_2010_2019_raw.colRegex(\"`^popestimate20\\d{2}$`\"),\n",
    "        us_counties_pop_est_2010_2019_raw.colRegex(\"`^births20\\d{2}$`\"),\n",
    "        us_counties_pop_est_2010_2019_raw.colRegex(\"`^deaths20\\d{2}$`\"),\n",
    "    ).join(\n",
    "        regions,\n",
    "        us_counties_pop_est_2010_2019_raw.region == regions.region,\n",
    "        'left'\n",
    "    ).join(\n",
    "        divisions,\n",
    "        us_counties_pop_est_2010_2019_raw.division == divisions.division,\n",
    "        'left'\n",
    "    )\n",
    "    .drop(regions.region)\n",
    "    .drop(divisions.division)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61852cc-cd8d-48d3-abce-b1159c9b777e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_fips',\n",
       " 'county_fips',\n",
       " 'state_name',\n",
       " 'county_name',\n",
       " 'region',\n",
       " 'division',\n",
       " 'census2010pop',\n",
       " 'estimatesbase2010',\n",
       " 'popestimate2010',\n",
       " 'popestimate2011',\n",
       " 'popestimate2012',\n",
       " 'popestimate2013',\n",
       " 'popestimate2014',\n",
       " 'popestimate2015',\n",
       " 'popestimate2016',\n",
       " 'popestimate2017',\n",
       " 'popestimate2018',\n",
       " 'popestimate2019',\n",
       " 'births2010',\n",
       " 'births2011',\n",
       " 'births2012',\n",
       " 'births2013',\n",
       " 'births2014',\n",
       " 'births2015',\n",
       " 'births2016',\n",
       " 'births2017',\n",
       " 'births2018',\n",
       " 'births2019',\n",
       " 'deaths2010',\n",
       " 'deaths2011',\n",
       " 'deaths2012',\n",
       " 'deaths2013',\n",
       " 'deaths2014',\n",
       " 'deaths2015',\n",
       " 'deaths2016',\n",
       " 'deaths2017',\n",
       " 'deaths2018',\n",
       " 'deaths2019',\n",
       " 'region_name',\n",
       " 'division_name']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b1adc-3cd2-4b17-9889-8a67cd1e1b0e",
   "metadata": {},
   "source": [
    "#### One problem is 'region_name' and 'division_name' columns are at the end, so need to re-arrange the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "595e422a-a7d0-410d-94c6-e37677ec1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    col('state_fips'),\n",
    "    col('county_fips'),\n",
    "    col('state_name'),\n",
    "    col('county_name'),\n",
    "    col('region_name'),\n",
    "    col('division_name'),\n",
    "    col('census2010pop'),\n",
    "    col('estimatesbase2010'),\n",
    "    us_counties_pop_est_2010_2019_raw.colRegex(\"`^popestimate20\\d{2}$`\"),\n",
    "    us_counties_pop_est_2010_2019_raw.colRegex(\"`^births20\\d{2}$`\"),\n",
    "    us_counties_pop_est_2010_2019_raw.colRegex(\"`^deaths20\\d{2}$`\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8fc015-b55c-4f0f-bd70-5ffe96a988ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_fips',\n",
       " 'county_fips',\n",
       " 'state_name',\n",
       " 'county_name',\n",
       " 'region_name',\n",
       " 'division_name',\n",
       " 'census2010pop',\n",
       " 'estimatesbase2010',\n",
       " 'popestimate2010',\n",
       " 'popestimate2011',\n",
       " 'popestimate2012',\n",
       " 'popestimate2013',\n",
       " 'popestimate2014',\n",
       " 'popestimate2015',\n",
       " 'popestimate2016',\n",
       " 'popestimate2017',\n",
       " 'popestimate2018',\n",
       " 'popestimate2019',\n",
       " 'births2010',\n",
       " 'births2011',\n",
       " 'births2012',\n",
       " 'births2013',\n",
       " 'births2014',\n",
       " 'births2015',\n",
       " 'births2016',\n",
       " 'births2017',\n",
       " 'births2018',\n",
       " 'births2019',\n",
       " 'deaths2010',\n",
       " 'deaths2011',\n",
       " 'deaths2012',\n",
       " 'deaths2013',\n",
       " 'deaths2014',\n",
       " 'deaths2015',\n",
       " 'deaths2016',\n",
       " 'deaths2017',\n",
       " 'deaths2018',\n",
       " 'deaths2019']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.select(selected_columns).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3f8f1-5e0a-4712-a33d-8b815abe0c45",
   "metadata": {},
   "source": [
    "#### The resulting dataframe above has the columns in the order we want, so now, let's write this dataframe as a PostgreSQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "660db0ef-b58c-4701-a47d-e65f2cb4d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/21 11:26:34 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    temp_df.select(selected_columns).orderBy(col('state_fips'), col('county_fips'))\n",
    "    # The following are needed to write this dataframe as a PostgreSQL table\n",
    "    .write.format(\"jdbc\")\n",
    "    .option(\"url\", url)\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"dbtable\", \"public.us_counties_pop_est_2010_2019_basic\")\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829658e8-7770-4b56-ab90-f8de4eaed476",
   "metadata": {},
   "source": [
    "#### Let's check if our new table has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163b6bc8-9bea-41e5-bb5b-cf00b1a0aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", pg_user)\n",
    "    .option(\"password\", pg_pwd)\n",
    "    .option(\"dbtable\", \"information_schema.tables\")\n",
    "    .load()\n",
    "    .filter(col('table_schema') == 'public')\n",
    "    .select(col('table_schema'), col('table_name'))\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e25862b-8566-4202-90fe-89ad7ddb510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.10 (PySpark 3.3.2)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
